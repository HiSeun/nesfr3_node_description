# Nesfr3 Overall Summary 
This document was made for arranging our overall concepts about nesfr3. We will discuss about the robot itself's composition, and discuss about each packages and nodes roles. 
* * *

## 1. Nesfr3 model composition
### 1.1. Sensors
* LiDAR (Ouster Lidar)
* Fisheye Camera
* Main Camera
* Encoder

### 1.2. Controllers
* Joystick
* 


## 2. Structural Diagram
Above figure shows the overall structural diagram of the nesfr3_workspace. It contains (*&(*&)^^ packages, and the topic message files are contained in ```nesfr3_msgs``` package.   
(*Other ```sensor_msgs```, ```geometry_msgs``` and etc. are not include in this diagram.)


## 3. Package Description
In this section we will discuss only about the main important packages and nodes. Their main roles are detecting, identifying, and tracking human.   

### 3.1. Cartograhper_ros (pkg)
### 3.1.1. Cartographer_node
Cartographer_node and Cartographer_occupancy_grid_node are the Google open source libraries. Cartographer is a system that provides real-time SLAM in 2D and 3D across multiple platforms and sensor configurations. Anyone can approach to its sources through [cartographer](https://github.com/cartographer-project/cartographer, "ROS_Wiki").  

#### A. Topics
* Subscribes
```
- nesfr3/1/lidar/points
- nesfr3/1/wheel_odom
- nesfr3/1/lidar_imu
```
```nesfr3/1/lidar/points``` is just ```sensor_msgs/PointCloud2``` type message, which contains the lidar points data.   
```nesfr3/1/wheel_odom``` is ```nav_msgs/Odometry``` type message. It would be generated by the encoder located in the wheel we guess.
```nesfr3/1/lidar_imu``` is just ```sensor_msgs/Imu``` type message. We don't know the reason why they changed the name of the topic as lidar_imu.    
It is not clear that whether the nesfr3 robot has the imu sensor itself or not.

* Publishes
```
- nesfr3/1/submap_list
```
```nesfr3/1/submap_list``` is the submap_list topic. Each step, cartograhper will create its own local map. And they save those local maps in this submap_lists and send to the cartographer_occupancy_grid_node. 

#### B. Role
The cartographer_node is the SLAM node used for online, real-time SLAM.
Using lidar data, it generates submaps and passes to the occupancy_grid_node.    

* * *
reference : [ROS API reference documentation](https://google-cartographer-ros.readthedocs.io/en/latest/ros_api.html, "google_cartographer")
* * *


### 3.2. Cartographer_occupancy_grid_node
#### A. Topics
* Subscribes
```
- nesfr3/1/submap_list
```

* Publishes
```
- nesfr3/1/map
```
```nesfr3/1/map``` is ```nav_msgs/OccupancyGrid``` type. We can visualize the SLAM in RViz by adding the topic name ```nesfr3/1/map```. 

#### B. Role
By receiving the submap_lists through the ```nesfr3/1/submap_list``` topic, this node will generate the global map.     
    
<img src = "/Shots/Cartographer1.png" width="300" height="300" align="center"></img>    

As you can see from the above image, the global map is not generated accurately, due to poor loop closure. 

* * *
reference : [ROS API reference documentation](https://google-cartographer-ros.readthedocs.io/en/latest/ros_api.html, "google_cartographer")
* * *

### 3.2. nesfr3_human_detection (pkg)
### 3.2.1. image_converter node
image_converter node subscribes orginal img data from fisheye camera and publish inference results creating child thread.    
Inference is done by TensorRT optimized SSD in child thread while main thread drawing detection results and displaying video.   

#### A. Topics
* Subscribes
```
- nesfr3/1/fisheye_camera/image_raw/image_topics
```
```fisheye_camera/image_raw/image_topics``` contains image data obtained by fisheye camera.

* Publishes
```
- nesfr3/1/bounding_boxes
```

#### B. Role
* **class TrtThread**
It implements the child thread (read images from cam to TRT inferencing). The child thread stores the input image and detectino results (global & condition variable)   

* **run()**
It runs until running flag is set to False in main thread. It detects human by function ```trt_ssd.detect(img, self.conf_th)```.    
Please refer ```detect.py``` .   

* **class image_converter** 
This class exists for parsing, and setting robot args. It publishes and subscribes image.   
   
* **callback(self,data)** 
Converting ROS image messages to OpenCV images, put cv_image to img_raw_queue, put bounidng boxes value   
     
* **bbox(box1, box2)** 
```bbox(box1, box2)```returns the iou of tow bbox.    
get the coordinates of bbox (if x1min>x1max x1min -w, else do nothing), get the coordinates of intersec rec (if x1min>x1max and x2min<x2max calculate iou1 as original(b1_x1 ..) and io2 as previous original box value(b1_x1+w) and set iou as max   

* **calculate_iou(coordinates..)** 
```bbox(box1, box2)``` finds intersection and calculate iou by ratio of area

* **duplicate_box_removal(bbox)** 
```duplicate_box_removal(bbox)``` removes bbox for same object

### 3.2. nesfr3_tracking (pkg)

### 3.3. bayes_people_tracker_(/nesfr3_tracking) (pkg)

### 3.4. pcl_transformer_(/nesfr3_tracking) (pkg)

### 3.5. object3d_detector_(/nesfr3_tracking) (pkg)

### 3.6. nesfr3_services (pkg)

### 3.7. 

## 4. Operation Pipeline
### 4.1. Detection

### 4.2. Identifying

### 4.3. Tracking
